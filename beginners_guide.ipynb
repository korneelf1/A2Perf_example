{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A beginners guide to using A2Perf\n",
    "This notebook walks through the steps and components necessary to submit your first A2Perf submission. \n",
    "\n",
    "## Installation\n",
    "First things first, we need to install A2Perf on our machine. A2Perf currently supports Python v3.7-3.9. To clone and set up the repository, you can use the following commands:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/Farama-Foundation/A2Perf.git\n",
    "cd A2Perf\n",
    "git submodule update --init --recursive\n",
    "pip install -e .\n",
    "pip install -r requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission folder\n",
    "In order to benchmark your reinforcement learning algorithms, your submission should have the following structure: \n",
    "```\n",
    "├── my_submission\n",
    "│   ├── __init__.py\n",
    "│   ├── train.py\n",
    "│   ├── inference.py\n",
    "│   ├── requirements.txt\n",
    "|   ├── your supporting files\n",
    "```\n",
    "### `__init__.py`\n",
    "The `__init__.py` file can be an empty file. \n",
    "\n",
    "### `train.py`\n",
    "The `train.py` file includes the function `train()`, which A2Perf calls for the training of your algorithm. An example of this file is shown below.\n",
    "\\\n",
    "\\\n",
    "First, we will import the necessary packages. For this tutorial, we will use the `quadruped_locomotion` environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the relevant A2Perf domain\n",
    "import rl_perf\n",
    "import rl_perf.domains.quadruped_locomotion\n",
    "\n",
    "# import gymnasium to create the environment\n",
    "import gymnasium as gym\n",
    "\n",
    "# import the abseil app to run the experiment\n",
    "from absl import app\n",
    "\n",
    "# import packages needed for your training\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define our training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    '''Include your training algorithm here.'''\n",
    "    # Create the environment\n",
    "    vec_env = make_vec_env(\"QuadrupedLocomotion-v0\", n_envs=8)\n",
    "\n",
    "    # Create the agent\n",
    "    model = PPO(\"MlpPolicy\", vec_env, verbose=1)\n",
    "    # Train the agent\n",
    "    model.learn(total_timesteps=25e3)\n",
    "    # Save the agent\n",
    "    model.save(\"ppo_cartpole\")\n",
    "\n",
    "    del model # remove to demonstrate saving and loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main function starts the training process of your reinforcement learning algortihm. This function is started with Abseil to facilitate the use of command line flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "  # The main function where the training process is initiated.\n",
    "  train()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  app.run(main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `inference.py`\n",
    "Next, the `inference.py` file is subsequently used for benchmarking the trained model.\n",
    "This file includes several functions.\n",
    "#### `load_model(env)`\n",
    "This function is intended to load and return the model. A2Perf passes the environment which is being tested. The `env` variable can therefore be used to specify any context needed for the model. \\\n",
    "\\\n",
    "Returns the trained model.\n",
    "\n",
    "#### `preprocess_observation(observation)`\n",
    "This function is called on the observation before feeding it to your model. If your model does not need any preprocessing, return the initial observation\n",
    "\\\n",
    "\\\n",
    "Returns (preprocessed) observation.\n",
    "\n",
    "#### `infer_once(model, observation)`\n",
    "Passes a single observation to the model. \\\n",
    "\\\n",
    "Returns the predicted action\n",
    "\n",
    "\n",
    "### `requirements.txt`\n",
    "In the requirements file, you can specify the dependencies required to run your submission. This may or may not include versioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 /Users/korneel/A2Perf/rl_perf/submission/main_submission.py --ginconfig=rl_perf/submission/configs/quadruped_locomotion/train.gin --participant_module_path=/Users/korneel/coding/A2Perf_example"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
